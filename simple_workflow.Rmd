---
title: "A Simple Workflow"
author: "Simon Goring, Socorro Dominguez Vidana"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup}
options(warn = -1)
suppressMessages(library(neotoma2))
suppressMessages(library(sf))
suppressMessages(library(geojsonsf))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(leaflet))
```

## Site Searches

### `get_sites()`

There are several ways to find sites in `neotoma2`, but we think of `sites` as being spatial objects primarily. They have names, locations, and are found within the context of geopolitical units, but within the API and the package, the site itself does not have associated information about taxa, dataset types or ages.  It is simply the container into which we add that information.  So, when we search for sites we can search by:

  * siteid
  * sitename
  * location
  * altitude (maximum and minimum)
  * geopolitical unit

#### Site names: `sitename="%Lait%"`

We may know exactly what site we're looking for ("Lac Mouton"), or have an approximate guess for the site name (for example, we know it's something like "Lait Lake", or "Lac du Lait", but we're not sure how it was entered specifically).

We use the general format: `get_sites(sitename="XXXXX")` for searching by name.

PostgreSQL (and the API) uses the percent sign as a wildcard.  So `"%Lait%"` would pick up ["Lac du Lait"](https://data.neotomadb.org/4180) for us (and would pick up "Lake Lait" and "This Old **Lait**y Hei-dee-ho Bog" if they existed).  Note that the search query is also case insensitive, so you could simply write `"%lait%"`.

```{r sitename}
spo_sites <- neotoma2::get_sites(sitename = "%Lait%")
spo_sites
plotLeaflet(spo_sites)
```

#### Location: `loc=c()`

The `neotoma` package used a bounding box for locations, structured as a vector of latitude and longitude values: `c(xmin, xmax, ymin, ymax)`.  The `neotoma2` R package supports both this simple bounding box, but also more complex spatial objects, using the [`sf` package](https://r-spatial.github.io/sf/). Using the `sf` package allows us to more easily work with raster and polygon data in R, and to select sites from more complex spatial objects.  The `loc` parameter works with the simple vector, [WKT](https://arthur-e.github.io/Wicket/sandbox-gmaps3.html), [geoJSON](http://geojson.io/#map=2/20.0/0.0) objects and native `sf` objects in R.  **Note however** that the `neotoma2` package is a wrapper for a simple API call using a URL ([api.neotomadb.org](https://api.neotomadb.org)), and URL strings can only be 1028 characters long, so the API cannot accept very long/complex spatial objects.

Looking for sites using a location:

```{r boundingBox}
cz <- list(geoJSON = '{"type": "Polygon",
        "coordinates": [[
            [12.40, 50.14],
            [14.10, 48.64],
            [16.95, 48.66],
            [18.91, 49.61],
            [15.24, 50.99],
            [12.40, 50.14]]]}',
        WKT = 'POLYGON ((12.4 50.14, 
                         14.1 48.64, 
                         16.95 48.66, 
                         18.91 49.61,
                         15.24 50.99,
                         12.4 50.14))',
        bbox = c(48.64, 50.99, 12.4, 18.91))

cz$sf <- geojsonsf::geojson_sf(cz$geoJSON)

cz_sites <- neotoma2::get_sites(loc = cz[[1]], all_data = TRUE)
```

You can always simply `plot()` the `sites` objects, but you will lose some of the geographic context.  The `plotLeaflet()` function returns a `leaflet()` map, and allows you to further customize it, or add additional spatial data (like our original bounding polygon):

```{r plotL}
neotoma2::plotLeaflet(cz_sites) %>% 
  leaflet::addPolygons(map = ., 
                       data = cz$sf, 
                       color = "green")
```

#### Site Helpers

If we look at the [UML diagram](https://en.wikipedia.org/wiki/Unified_Modeling_Language) for the objects in the `neotoma2` R package we can see that there are a set of functions that can operate on `sites`.  As we add to `sites` objects, using `get_datasets()` or `get_downloads()`, we are able to use more of these helper functions. As it is, we can take advantage of sunctions like `summary()` to get a more complete sense of the types of data we have as part of this set of sites.  The following code gives the summary table. We do some R magic here to change the way the data is displayed (turning it into a `datatable()` object), but the main piece is the `summary()` call.

```{r summary_sites, eval=FALSE}
neotoma2::summary(cz_sites) %>%
  DT::datatable()
```

### Searching for datasets:

We know that collection units and datasets are contained within sites.  Similarly, a `sites` object contains `collectionunits` which contain `datasets`. From the table above we can see that some of the sites we've looked at contain pollen records. That said, we only have the `sites`, it's just that (for convenience) the `sites` API returns some information about datasets so to make it easier to navigate the records.

With a `sites` object we can directly call `get_datasets()`, to pull in more metadata about the datasets.  At any time we can use `datasets()` to get more information about any datasets that a `sites` object may contain.  Compare the output of `datasets(cz_sites)` to the output of a similar call using the following:

```{r datasetsFromSites}
cz_datasets <- neotoma2::get_datasets(cz_sites, all_data = TRUE)
datasets(cz_datasets) %>% 
  as.data.frame() %>% 
  DT::datatable(data = .)
```

If we choose to pull in information about only a single dataset type, or if there is additional filtering we want to do before we download the data, we can use the `filter()` function.  For example, if we only want pollen records, we can filter:

```{r downloads}
cz_pollen <- cz_datasets %>% 
  neotoma2::filter(datasettype == "pollen")

neotoma2::summary(cz_pollen) %>% DT::datatable(data = .)
```

We can see now that the data table looks different, and there are fewer total sites.

Note that R is sensitive to the order in which packages are loaded.  Using `neotoma2::` tells R explicitly that you want to use the `neotoma2` package to fun the `filter()` operation.  `filter()` exists in other packages as well, such as `dplyr`, so if you see an error that looks like:

```bash
Error in UseMethod("filter") : 
  no applicable method for 'filter' applied to an object of class "sites"
```

it's likely that the wrong package is trying to run `filter()`.

### Pulling in the `sample()` data.

Because sample data adds a lot of overhead (for the Czech pollen data, the object that includes the dataset with samples is 20 times larger than the `dataset` alone), we try to call `get_downloads()` after we've done our preliminary filtering. The following call can take some time, but we've frozen the object as an RDS data file. You can run this command on your own, and let it run for a bit, or you can just load the object in.

```{r taxa}
# cz_dl <- cz_pollen %>% get_downloads(all_data = TRUE)
cz_dl <- readRDS('czDownload.RDS')
```


We can do also for one element:
```{r taxa2}
head(as.data.frame(neotoma2::taxa(cz_pollen[[1]])))
```

### Doing a Basic Analysis

1. Getting all pollen

```{r pollen}
all_pollen <- neotoma2::get_datasets(datasettype = "pollen",
                                     limit = 100)

# all_pollen <- get_datasets(datasettype="pollen", all_data = TRUE) # Takes about 20+ minutes
```
_

```{r}
neotoma2::plot(all_pollen)
```

2. Getting the data
```{r dl}
pollen_dl <- neotoma2::get_downloads(all_pollen) # Takes a couple of minutes 
```

3. Get the samples

```{r samp}
pollen_samp <- neotoma2::samples(pollen_dl)
head(pollen_samp)
```

Using Spatial-based Data (July max temperature)

```{r}
spatial <- sf::st_as_sf(pollen_samp, 
                        coords = c("long", "lat"),
                        crs = "+proj=longlat +datum=WGS84")
spatial
```

```{r worldTmax}
worldTmax <- raster::getData('worldclim', var = 'tmax', res = 10)
worldTmax
```

```{r raster}
pollen_samp$tmax7 <- raster::extract(worldTmax, spatial)[,7]
head(pollen_samp)
```

#### Choosing Taxa

```{r maxsamp}
maxsamp <- pollen_samp %>% dplyr::distinct(siteid, .keep_all = TRUE) %>% 
  dplyr::select(tmax7)
head(maxsamp)
```

Top 10
```{r topten}


topten <- pollen_samp %>% 
  dplyr::group_by(variablename) %>% 
  dplyr::summarise(n = dplyr::n()) %>% 
  dplyr::arrange(desc(n))
topten
```

```{r po_subsamp}
pollen_subsamp <- pollen_samp %>% 
  dplyr::filter(variablename %in% topten$variablename[1:10])
head(pollen_subsamp)
```

Plot your results!

```{r ggplot}
ggplot() +
  geom_density(data = pollen_subsamp,
               aes(x = round(tmax7 / 10, 0)), col = 2) +
  facet_wrap(~variablename) +
  geom_density(data = maxsamp, aes(x = tmax7 / 10)) +
  xlab("Maximum July Temperature") +
  ylab("Kernel Density")
```
